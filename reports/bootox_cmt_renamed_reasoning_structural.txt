[ Evaluation report 'Q01 (Persons)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q02 (1st Authors)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q03 (Co-Authors)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q04 (Conferences)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q06 (Reviewers)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q07 (Documents)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q08 (Papers)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q09 (Abstracts)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q10 (Reviews)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q11 (Program Committees)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q12 (PC Members)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q14 (PC Chairs)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q20 (Peoples' Complete Names)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q23 (E-mail Addresses)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q25 (Conference Names)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q26 (Start Dates)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q28 (PC Names)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q32 (Paper IDs)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q34 (Paper Titles)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q35 (Abstract IDs)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q36 (Abstract Titles)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q38 (Review Texts)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q40 (Conference URLs, Linked from Conference)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q41 (Papers <-> Authors)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q42 (Papers <-> Co-Authors)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q43 (Papers <-> Reviewers)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q45 (Reviewers <-> Reviews)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q46 (PCs <-> Persons)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q48 (Persons <-> Conferences)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'All (AVG)': score = 0.7586206793785095; precision = 0.7586206793785095, recall = 0.7586206793785095]
[ Evaluation report 'path-3 (AVG)': score = 0.3333333432674408; precision = 0.3333333432674408, recall = 0.3333333432674408]
[ Evaluation report 'path-2 (AVG)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'path-1 (AVG)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'other-table (AVG)': score = 0.5; precision = 0.5, recall = 0.5]
[ Evaluation report '1-1 (AVG)': score = 0.9166666865348816; precision = 0.9166666865348816, recall = 0.9166666865348816]
[ Evaluation report 'attrib (AVG)': score = 0.7272727489471436; precision = 0.7272727489471436, recall = 0.7272727489471436]
[ Evaluation report 'in-table (AVG)': score = 0.8571428656578064; precision = 0.8571428656578064, recall = 0.8571428656578064]
[ Evaluation report 'superclass (AVG)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'path-4 (AVG)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'link (AVG)': score = 0.5; precision = 0.5, recall = 0.5]
[ Evaluation report 'path-X (AVG)': score = 0.40000003576278687; precision = 0.4000000059604645, recall = 0.4000000059604645]
[ Evaluation report 'class (AVG)': score = 0.9166666865348816; precision = 0.9166666865348816, recall = 0.9166666865348816]
