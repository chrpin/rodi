[ Evaluation report 'Q01 (Persons)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q02 (1st Authors)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q03 (Co-Authors)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q04 (Conferences)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q06 (Reviewers)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q07 (Documents)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q08 (Papers)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q09 (Abstracts)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q10 (Reviews)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q11 (Program Committees)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q12 (PC Members)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q14 (PC Chairs)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'Q20 (Peoples' Complete Names)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q23 (E-mail Addresses)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q25 (Conference Names)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q26 (Start Dates)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q28 (PC Names)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q32 (Paper IDs)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q34 (Paper Titles)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q35 (Abstract IDs)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q36 (Abstract Titles)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q38 (Review Texts)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q40 (Conference URLs, Linked from Conference)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q41 (Papers <-> Authors)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q42 (Papers <-> Co-Authors)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q43 (Papers <-> Reviewers)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q45 (Reviewers <-> Reviews)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q46 (PCs <-> Persons)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'Q48 (Persons <-> Conferences)': score = 1.0; precision = 1.0, recall = 1.0]
[ Evaluation report 'All (AVG)': score = 0.3103448152542114; precision = 0.3103448152542114, recall = 0.3103448152542114]
[ Evaluation report 'path-3 (AVG)': score = 0.3333333432674408; precision = 0.3333333432674408, recall = 0.3333333432674408]
[ Evaluation report 'path-2 (AVG)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'path-1 (AVG)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'other-table (AVG)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report '1-1 (AVG)': score = 0.6666666865348816; precision = 0.6666666865348816, recall = 0.6666666865348816]
[ Evaluation report 'attrib (AVG)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'in-table (AVG)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'superclass (AVG)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'path-4 (AVG)': score = NaN; precision = 0.0, recall = 0.0]
[ Evaluation report 'link (AVG)': score = 0.1666666716337204; precision = 0.1666666716337204, recall = 0.1666666716337204]
[ Evaluation report 'path-X (AVG)': score = 0.20000001788139343; precision = 0.20000000298023224, recall = 0.20000000298023224]
[ Evaluation report 'class (AVG)': score = 0.6666666865348816; precision = 0.6666666865348816, recall = 0.6666666865348816]
